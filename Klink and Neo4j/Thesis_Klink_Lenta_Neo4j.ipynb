{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading libraries"
      ],
      "metadata": {
        "id": "y4fQwS1LPjhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download ru_core_news_sm\n",
        "!pip install neo4j"
      ],
      "metadata": {
        "id": "vCOaIrGfNRzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import shutil\n",
        "from neo4j import GraphDatabase"
      ],
      "metadata": {
        "id": "lUKwuDVVNLOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking file with the extracted terms"
      ],
      "metadata": {
        "id": "HRt-NPRTPnBv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEOAEBgIDrCl"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('extracted_terms_with_links.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vocabulary of keywords for Klink is the extracted terms"
      ],
      "metadata": {
        "id": "tA6S_JCLP3ZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = df['term']"
      ],
      "metadata": {
        "id": "Q2GNU67CNVlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing news data via spacy"
      ],
      "metadata": {
        "id": "RxL_gdewP89p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ten_years = pd.read_csv('ten_years_with_good_format.csv')\n",
        "ten_years.fillna('', inplace = True)"
      ],
      "metadata": {
        "id": "2WBAdDiBNW7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('ru_core_news_sm')"
      ],
      "metadata": {
        "id": "HED4UYuqNaAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_full_news = []\n",
        "\n",
        "for index, row in ten_years.iterrows():\n",
        "    doc = nlp(str(row['full_news']))\n",
        "\n",
        "    lemmatized = ' '.join(token.lemma_ for token in doc)\n",
        "\n",
        "    lemmatized_full_news.append(lemmatized)"
      ],
      "metadata": {
        "id": "HSvIBTgINb_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally saving the preprocessed data"
      ],
      "metadata": {
        "id": "k6LA5ainQBQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_lemmatized = pd.DataFrame(lemmatized_full_news, columns = ['lemm_full_news'])\n",
        "\n",
        "full_lemmatized['date'] = ten_years['date']\n",
        "full_lemmatized['organizations'] = ten_years['organizations']\n",
        "full_lemmatized['persons'] = ten_years['persons']\n",
        "\n",
        "full_lemmatized.to_csv('all_news_lemmatized.csv', index = False)"
      ],
      "metadata": {
        "id": "t3AlN2KCNgVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing modules and creating the ontology"
      ],
      "metadata": {
        "id": "_-Nsa89AQHFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ontology_module import create_ontology\n",
        "from ontology_module import visualise_ontology"
      ],
      "metadata": {
        "id": "SenE7NYhOBG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "created = create_ontology(full_lemmatized['lemm_full_news'], vocab, 20)\n",
        "written = visualise_ontology(created, True, 20)"
      ],
      "metadata": {
        "id": "MTORct4kOFo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to save ontology into two csv files: one for nodes and one for edges"
      ],
      "metadata": {
        "id": "MxCfKCaUQK3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_to_csv(vocab, node_file, edge_file):\n",
        "\n",
        "    all_edges = []\n",
        "    all_nodes = set()\n",
        "\n",
        "    for word in vocab.keys():\n",
        "        for i in vocab[word]:\n",
        "            all_edges.append([i[0], word, i[1]['weight']])\n",
        "            all_nodes.add(i[0])\n",
        "        all_nodes.add(word)\n",
        "\n",
        "    nodes = pd.DataFrame(all_nodes, columns = ['Word'])\n",
        "    edges = pd.DataFrame(all_edges, columns = ['Word', 'Subtopic_of', 'Weight'])\n",
        "\n",
        "    nodes.to_csv(node_file, index = False)\n",
        "    edges.to_csv(edge_file, index = False)"
      ],
      "metadata": {
        "id": "F2sO5ErxOQf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the ontology"
      ],
      "metadata": {
        "id": "TCxbF2U1QRlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_name = 'klink_lenta' + '_nodes.csv'\n",
        "edge_name = 'klink_lenta' + '_edges.csv'\n",
        "\n",
        "graph_to_csv(written, node_name, edge_name)"
      ],
      "metadata": {
        "id": "j5aaOPVqORTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uploading the ontology into Neo4j"
      ],
      "metadata": {
        "id": "wwQSaORbQTfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#give necessary directories where the edges file is located and where it is\n",
        "#supposed to go\n",
        "src = r\"C:\\Users\\anutk\\Project2024\\Klink-2_and_Lenta\\klink_lenta_edges.csv\"\n",
        "dst = r\"C:\\Users\\anutk\\.Neo4jDesktop\\relate-data\\dbmss\\dbms-f12510d2-d551-4266-b729-ac22ffeb04b4\\import\\klink_lenta_edges.csv\"\n",
        "\n",
        "shutil.copyfile(src, dst)"
      ],
      "metadata": {
        "id": "Yl_d1FLmOTn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#give necessary directories where the nodes file is located and where it is\n",
        "#supposed to go\n",
        "src = r\"C:\\Users\\anutk\\Project2024\\Klink-2_and_Lenta\\klink_lenta_nodes.csv\"\n",
        "dst = r\"C:\\Users\\anutk\\.Neo4jDesktop\\relate-data\\dbmss\\dbms-f12510d2-d551-4266-b729-ac22ffeb04b4\\import\\klink_lenta_nodes.csv\"\n",
        "\n",
        "shutil.copyfile(src, dst)"
      ],
      "metadata": {
        "id": "mBXPiWDWPGhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class for establishing a connection with Neo4j server\n",
        "\n",
        " [Source code]((https://habr.com/ru/articles/650623/)"
      ],
      "metadata": {
        "id": "bG_UnhBgQ02n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neo4jConnection:\n",
        "    def __init__(self, uri, user, password):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    def close(self):\n",
        "        if self.driver is not None:\n",
        "            self.driver.close()\n",
        "\n",
        "    def query(self, query, db=None):\n",
        "        assert self.driver is not None, \"Driver not initialized!\"\n",
        "        session = None\n",
        "        response = None\n",
        "        try:\n",
        "            session = self.driver.session(database=db) if db is not None else self.driver.session()\n",
        "            response = list(session.run(query))\n",
        "        except Exception as e:\n",
        "            print(\"Query failed:\", e)\n",
        "        finally:\n",
        "            if session is not None:\n",
        "                session.close()\n",
        "        return response"
      ],
      "metadata": {
        "id": "dGNB0JJqPKUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the database and uploading the ontology"
      ],
      "metadata": {
        "id": "-_jLoi6XRHDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn = Neo4jConnection(uri=\"bolt://localhost:7687\", user=\"neo4j\", password=\"12345678\")\n",
        "conn.query(\"CREATE OR REPLACE DATABASE testDb\")"
      ],
      "metadata": {
        "id": "ArSXvDbsPVdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_string = '''\n",
        "LOAD CSV WITH HEADERS FROM 'file:///klink_lenta_nodes.csv' AS line FIELDTERMINATOR ','\n",
        "CREATE (word:Word {word: line.Word});\n",
        "'''\n",
        "conn.query(query_string, db='testDb')"
      ],
      "metadata": {
        "id": "nElQT9GkPXTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_string = '''\n",
        "LOAD CSV WITH HEADERS FROM 'file:///klink_lenta_edges.csv' AS line FIELDTERMINATOR ','\n",
        "MATCH (word1:Word {word: line.Word}), (word2:Word {word: line.Subtopic_of})\n",
        "MERGE (word1)<-[:SUBTOPIC]-(word2);\n",
        "'''\n",
        "conn.query(query_string, db='testDb')"
      ],
      "metadata": {
        "id": "lsCA2fW3Pd0w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}