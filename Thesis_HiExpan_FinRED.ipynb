{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "HiExpan is implemented using older version of libraries than those that are available in Colab, so they are reuploaded"
      ],
      "metadata": {
        "id": "c4ka5A5xZX1p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cuD08egmRc3m",
        "outputId": "a56e3f25-5097-4712-b5ca-4baf8acb04d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.7-minimal libpython3.7-stdlib mailcap mime-support\n",
            "  python3.7-minimal\n",
            "Suggested packages:\n",
            "  python3.7-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.7-minimal libpython3.7-stdlib mailcap mime-support python3.7\n",
            "  python3.7-minimal\n",
            "0 upgraded, 6 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 4,698 kB of archives.\n",
            "After this operation, 17.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.7-minimal amd64 3.7.17-1+jammy1 [608 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.7-minimal amd64 3.7.17-1+jammy1 [1,837 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.7-stdlib amd64 3.7.17-1+jammy1 [1,864 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.7 amd64 3.7.17-1+jammy1 [362 kB]\n",
            "Fetched 4,698 kB in 5s (984 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.7-minimal:amd64.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.7-minimal_3.7.17-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.7-minimal:amd64 (3.7.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.7-minimal.\n",
            "Preparing to unpack .../1-python3.7-minimal_3.7.17-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.7-minimal (3.7.17-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../3-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.7-stdlib:amd64.\n",
            "Preparing to unpack .../4-libpython3.7-stdlib_3.7.17-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.7-stdlib:amd64 (3.7.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.7.\n",
            "Preparing to unpack .../5-python3.7_3.7.17-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.7 (3.7.17-1+jammy1) ...\n",
            "Setting up libpython3.7-minimal:amd64 (3.7.17-1+jammy1) ...\n",
            "Setting up python3.7-minimal (3.7.17-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.7-stdlib:amd64 (3.7.17-1+jammy1) ...\n",
            "Setting up python3.7 (3.7.17-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install python3.7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtMiODh-Rl1F",
        "outputId": "bb729904-4609-492b-b963-75a08f2bcecb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/bin/python3.7 to provide /usr/bin/python3 (python3) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2-jgB8mMRofL",
        "outputId": "1eba56de-a251-48f4-b1a8-f5d89bcfaf9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-pip' instead of 'pip'\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,967 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.1 [339 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.4 [1,305 kB]\n",
            "Fetched 1,677 kB in 4s (472 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-setuptools.\n",
            "(Reading database ... 122563 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install python3.7-distutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aiLHbCokRqSM",
        "outputId": "50ac127b-6096-4423-a09a-d518c68d5791"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3.7-lib2to3\n",
            "The following NEW packages will be installed:\n",
            "  python3.7-distutils python3.7-lib2to3\n",
            "0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 313 kB of archives.\n",
            "After this operation, 1,229 kB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.7-lib2to3 all 3.7.17-1+jammy1 [124 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.7-distutils all 3.7.17-1+jammy1 [189 kB]\n",
            "Fetched 313 kB in 3s (121 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3.7-lib2to3.\n",
            "(Reading database ... 123425 files and directories currently installed.)\n",
            "Preparing to unpack .../python3.7-lib2to3_3.7.17-1+jammy1_all.deb ...\n",
            "Unpacking python3.7-lib2to3 (3.7.17-1+jammy1) ...\n",
            "Selecting previously unselected package python3.7-distutils.\n",
            "Preparing to unpack .../python3.7-distutils_3.7.17-1+jammy1_all.deb ...\n",
            "Unpacking python3.7-distutils (3.7.17-1+jammy1) ...\n",
            "Setting up python3.7-lib2to3 (3.7.17-1+jammy1) ...\n",
            "Setting up python3.7-distutils (3.7.17-1+jammy1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzipping the archive with the HiExpan implementation\n",
        "\n",
        "[Source](https://github.com/mickeysjm/HiExpan/tree/master)"
      ],
      "metadata": {
        "id": "6_Gu7zpbZkY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip HiExpan-master.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YzcHI3pyRskf",
        "outputId": "17e68f47-c866-47be-a944-864ef9235800"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  HiExpan-master.zip\n",
            " extracting: HiExpan-master/.gitignore  \n",
            "   creating: HiExpan-master/data/\n",
            "   creating: HiExpan-master/data/sample_dataset/\n",
            "   creating: HiExpan-master/data/sample_dataset/intermediate/\n",
            "  inflating: HiExpan-master/data/sample_dataset/intermediate/entity2id.txt  \n",
            "  inflating: HiExpan-master/data/sample_dataset/intermediate/sentences.json  \n",
            "   creating: HiExpan-master/data/sample_dataset/source/\n",
            "  inflating: HiExpan-master/data/sample_dataset/source/corpus.txt.txt  \n",
            "   creating: HiExpan-master/data/source/\n",
            "  inflating: HiExpan-master/data/source/corpus.txt  \n",
            "   creating: HiExpan-master/KB/\n",
            "  inflating: HiExpan-master/KB/README.md  \n",
            "  inflating: HiExpan-master/LICENSE  \n",
            "  inflating: HiExpan-master/README.md  \n",
            " extracting: HiExpan-master/requirements.txt  \n",
            "   creating: HiExpan-master/src/\n",
            "   creating: HiExpan-master/src/corpusProcessing/\n",
            "  inflating: HiExpan-master/src/corpusProcessing/annotateNLPFeature_new.py  \n",
            "  inflating: HiExpan-master/src/corpusProcessing/corpusProcess_new.sh  \n",
            "  inflating: HiExpan-master/src/corpusProcessing/keyTermExtraction.py  \n",
            "  inflating: HiExpan-master/src/corpusProcessing/multiprocess_annotateNLPFeature.py  \n",
            "  inflating: HiExpan-master/src/corpusProcessing/parseCorpus.py  \n",
            "  inflating: HiExpan-master/src/corpusProcessing/README.md  \n",
            "   creating: HiExpan-master/src/featureExtraction/\n",
            "  inflating: HiExpan-master/src/featureExtraction/extractEidDocPairFeature.py  \n",
            "  inflating: HiExpan-master/src/featureExtraction/extractSkipGramFeature.py  \n",
            "  inflating: HiExpan-master/src/featureExtraction/extractTypeFeature.py  \n",
            "  inflating: HiExpan-master/src/featureExtraction/learnEmbedFeature.py  \n",
            "  inflating: HiExpan-master/src/featureExtraction/main.sh  \n",
            "  inflating: HiExpan-master/src/featureExtraction/probase3.py  \n",
            "  inflating: HiExpan-master/src/featureExtraction/README.md  \n",
            "  inflating: HiExpan-master/src/featureExtraction/transformFeatures.py  \n",
            "   creating: HiExpan-master/src/HiExpan-new/\n",
            "  inflating: HiExpan-master/src/HiExpan-new/dataLoader.py  \n",
            "  inflating: HiExpan-master/src/HiExpan-new/depthExpan.py  \n",
            "  inflating: HiExpan-master/src/HiExpan-new/main.py  \n",
            "  inflating: HiExpan-master/src/HiExpan-new/seedLoader.py  \n",
            "  inflating: HiExpan-master/src/HiExpan-new/set_expan.py  \n",
            "  inflating: HiExpan-master/src/HiExpan-new/treeNode.py  \n",
            "  inflating: HiExpan-master/src/HiExpan-new/util.py  \n",
            "   creating: HiExpan-master/src/SetExpan-new/\n",
            "  inflating: HiExpan-master/src/SetExpan-new/set_expan_main.py  \n",
            "  inflating: HiExpan-master/src/SetExpan-new/set_expan_standalone.py  \n",
            "   creating: HiExpan-master/src/tools/\n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/auto_phrase.sh  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/compile.sh  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/data/\n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/data/AR/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/AR/stopwords.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/AR/wiki_all.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/AR/wiki_quality.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/BAD_POS_TAGS.txt  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/data/CN/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/CN/stopwords.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/CN/wiki_all.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/CN/wiki_quality.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/DBLP.txt  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/data/EN/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/EN/DBLP.5K.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/EN/stopwords.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/EN/wiki_all.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/EN/wiki_quality.txt  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/data/ES/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/ES/stopwords.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/ES/wiki_all.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/data/ES/wiki_quality.txt  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/docker/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/docker/Dockerfile  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/docker/make.sh  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/LICENSE  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/Makefile  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/models/\n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/models/DBLP/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/models/DBLP/AutoPhrase.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/models/DBLP/AutoPhrase_multi-words.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/models/DBLP/AutoPhrase_single-word.txt  \n",
            " extracting: HiExpan-master/src/tools/AutoPhrase/models/DBLP/language.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/models/DBLP/segmentation.model  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/models/DBLP/token_mapping.txt  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/models/deep_learning/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/models/deep_learning/AutoPhrase.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/models/deep_learning/AutoPhrase_multi-words.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/models/deep_learning/AutoPhrase_single-word.txt  \n",
            " extracting: HiExpan-master/src/tools/AutoPhrase/models/deep_learning/language.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/models/deep_learning/segmentation.model  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/models/deep_learning/segmentation.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/models/deep_learning/token_mapping.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/phrasal_segmentation.sh  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/README.md  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/src/\n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/src/classification/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/classification/feature_extraction.h  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/classification/label_generation.h  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/classification/predict_quality.h  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/classification/random_forest.h  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/src/clustering/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/clustering/clustering.h  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/src/data/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/data/documents.h  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/data/dump.h  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/src/frequent_pattern_mining/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/frequent_pattern_mining/frequent_pattern_mining.h  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/main.cpp  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/src/model_training/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/model_training/segmentation.h  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/segment.cpp  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/src/utils/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/utils/commandline_flags.h  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/utils/parameters.h  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/utils/random.h  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/src/utils/utils.h  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/tools/\n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/build.xml  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/build/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/build/ChineseTagger.class  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/build/SpecialTagger.class  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/build/StandardTagger.class  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/build/Tokenizer$1.class  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/build/Tokenizer$Output.class  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/build/Tokenizer.class  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/lib/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/lib/ansj_seg-5.0.2-all-in-one.jar  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/lib/jsonic-1.2.0.jar  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/lib/langdetect.jar  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/lib/lucene-analyzers-common-5.2.0.jar  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/lib/lucene-analyzers-kuromoji-5.4.0.jar  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/lib/lucene-analyzers-smartcn-5.4.0.jar  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/lib/lucene-core-5.4.0.jar  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/lib/slf4j-api.jar  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/lib/slf4j-simple.jar  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/readme(tokenizer).txt  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/cjk_punctuation_mapping.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/indo_european_punctuation_mapping.txt  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/ar  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/bg  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/bn  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/ca  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/cs  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/da  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/de  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/el  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/en  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/es  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/et  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/fa  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/fi  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/fr  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/gu  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/he  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/hi  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/hr  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/hu  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/id  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/it  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/ja  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/ko  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/lt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/lv  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/mk  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/ml  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/nl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/no  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/pa  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/pl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/pt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/ro  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/ru  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/si  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/sq  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/sv  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/ta  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/te  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/th  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/tl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/tr  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/uk  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/ur  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/vi  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/zh-cn  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/resources/profiles.sm/zh-tw  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/src/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/tokenizer/src/Tokenizer.java  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/\n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/bin/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/bin/separate-punctuation  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/bin/train-tree-tagger  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/bin/tree-tagger  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/bin/tree-tagger-flush  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/bin/tree-tagger-linux  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/bin/tree-tagger-linux-old  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/bin/tree-tagger-mac  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/#tagger-chunker-spanish#  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/chinese-2c.utf8  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/chinese-3c.utf8  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/chunker-read-lemma.perl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/chunker-write-lemma.perl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/create-chunker-par-file  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/create-pos-par-file  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/filter-chunker-output.perl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/filter-chunker-output-french.perl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/filter-chunker-output-german.perl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/filter-coordinate-output.perl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/filter-german-tags  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/lookup.perl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/make-chunk-lex.perl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/make-lex.perl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/mwl-lookup.perl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/portuguese-post-tagging  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/portuguese-splitter.perl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/segmenter.pm  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/segment-zh.perl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/split-romanian.perl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tagger-chunker-english  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tagger-chunker-french  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tagger-chunker-german  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tagger-chunker-spanish  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tokenize.pl  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-bulgarian  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-chinese  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-dutch  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-english  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-estonian  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-finnish  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-french  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-galician  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-german  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-italian  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-latin  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-polish  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-portuguese  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-portuguese-finegrained  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-romanian  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-russian  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-slovak  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-slovenian  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-spanish  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/tree-tagger-swahili  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/cmd/utf8-tokenize.perl  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/doc/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/doc/nemlap94.ps  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/doc/sigdat95.ps  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/download_parameter_files.sh  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/FILES  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/bulgarian-abbreviations  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/bulgarian-mwls  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/dutch-abbreviations  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/english-abbreviations  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/english-utf8.par  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/estonian-abbreviations-utf8  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/estonian-mwls-utf8  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/finnish-abbreviations-utf8  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/french-abbreviations  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/french-abbreviations-utf8  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/galician-abbreviations-utf8  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/galician-mwls  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/german-abbreviations  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/german-abbreviations-utf8  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/german-lexicon.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/german-lexicon-utf8.txt  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/italian-abbreviations  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/latin-abbreviations  \n",
            " extracting: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/latin-mwls  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/polish-abbreviations-utf8  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/portuguese-abbreviations-utf8  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/romanian-abbreviations  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/romanian-tokens  \n",
            " extracting: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/spanish-abbreviations  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/spanish-mwls  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/spanish-mwls-utf8  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/lib/swahili-abbreviations  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/LICENSE  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/merge_tagged_files.py  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/pos_tag.sh  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/prepare_untagged_files.py  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/README  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/treetagger/README.script  \n",
            "   creating: HiExpan-master/src/tools/AutoPhrase/tools/wiki_entities/\n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/wiki_entities/high_quality_phrase_filter.py  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/wiki_entities/README.md  \n",
            "  inflating: HiExpan-master/src/tools/AutoPhrase/tools/wiki_entities/wiki_all_phrase_filter.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the necessary libraries with versions compatible with HiExpan"
      ],
      "metadata": {
        "id": "AJM4G6XRZyL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r HiExpan-master/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e-T1HaglRvJx",
        "outputId": "3fe3ed9c-2b41-415a-fda3-fe9288ee87e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gensim\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open>=1.8.1\n",
            "  Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrapt\n",
            "  Downloading wrapt-1.16.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tqdm, numpy, smart-open, scipy, gensim\n",
            "Successfully installed gensim-4.2.0 numpy-1.21.6 scipy-1.7.3 smart-open-7.0.4 tqdm-4.66.4 wrapt-1.16.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy==2.1.9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "collapsed": true,
        "id": "UtMJELXORxKA",
        "outputId": "7d4255a8-5d13-447b-954a-8eef6f43c517"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy==2.1.9\n",
            "  Downloading spacy-2.1.9-cp37-cp37m-manylinux1_x86_64.whl (30.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blis<0.3.0,>=0.2.2\n",
            "  Downloading blis-0.2.4-cp37-cp37m-manylinux1_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting thinc<7.1.0,>=7.0.8\n",
            "  Downloading thinc-7.0.8-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting preshed<2.1.0,>=2.0.1\n",
            "  Downloading preshed-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wasabi<1.1.0,>=0.2.0\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0\n",
            "  Downloading murmurhash-1.0.10-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Collecting requests<3.0.0,>=2.13.0\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting srsly<1.1.0,>=0.0.6\n",
            "  Downloading srsly-1.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (367 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.0/368.0 KB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting plac<1.0.0,>=0.9.6\n",
            "  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.9) (1.21.6)\n",
            "Collecting cymem<2.1.0,>=2.0.2\n",
            "  Downloading cymem-2.0.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.8/136.8 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from thinc<7.1.0,>=7.0.8->spacy==2.1.9) (4.66.4)\n",
            "Installing collected packages: wasabi, plac, cymem, urllib3, srsly, preshed, murmurhash, idna, charset-normalizer, certifi, blis, thinc, requests, spacy\n",
            "Successfully installed blis-0.2.4 certifi-2024.2.2 charset-normalizer-3.3.2 cymem-2.0.8 idna-3.7 murmurhash-1.0.10 plac-0.9.6 preshed-2.0.1 requests-2.31.0 spacy-2.1.9 srsly-1.0.7 thinc-7.0.8 urllib3-2.0.7 wasabi-0.10.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi"
                ]
              },
              "id": "c706f23a83b945b5a35d47de3680a210"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FaJ_gX-bR1lD",
        "outputId": "05bfcda4-1f80-4a07-c57c-1cccd7c38cfe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: en_core_web_sm\n",
            "  Building wheel for en_core_web_sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en_core_web_sm: filename=en_core_web_sm-2.1.0-py3-none-any.whl size=11074433 sha256=20be3e739d69918984cdc904ab4476adfc4eef8f64c74bff2d350a4ccc978341\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oavwekum/wheels/59/4f/8c/0dbaab09a776d1fa3740e9465078bfd903cc22f3985382b496\n",
            "Successfully built en_core_web_sm\n",
            "Installing collected packages: en_core_web_sm\n",
            "Successfully installed en_core_web_sm-2.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "55NbQd6LZ68A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/HiExpan-master/src/corpusProcessing'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycrAS4dbR5A7",
        "outputId": "085f8fe8-add7-4e6c-ca84-8b1333e48257"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HiExpan-master/src/corpusProcessing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x /content/HiExpan-master/src/corpusProcessing/corpusProcess_new.sh\n",
        "!/content/HiExpan-master/src/corpusProcessing/corpusProcess_new.sh FINRED 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hIiR8VnrR9Vh",
        "outputId": "60ab9bd2-d98b-41c7-f7a5-28c9152da1ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HiExpan-master/src/corpusProcessing\n",
            "\u001b[32m===Corpus Name: FINRED===\u001b[m\n",
            "\u001b[32m===Current Path: /content/HiExpan-master/src/corpusProcessing===\u001b[m\n",
            "\u001b[32m===Cleaning input corpus===\u001b[m\n",
            "\u001b[32m===Running AutoPhrase===\u001b[m\n",
            "mkdir -p bin\n",
            "g++ -std=c++11 -Wall -O3 -msse2  -fopenmp  -I.. -pthread -lm -Wno-unused-result -Wno-sign-compare -Wno-unused-variable -Wno-parentheses -Wno-format -o bin/segphrase_train src/main.cpp\n",
            "g++ -std=c++11 -Wall -O3 -msse2  -fopenmp  -I.. -pthread -lm -Wno-unused-result -Wno-sign-compare -Wno-unused-variable -Wno-parentheses -Wno-format -o bin/segphrase_segment src/segment.cpp\n",
            "\u001b[32m===RAW_TRAIN: ../../../data/FINRED/source/corpus.clean.txt===\u001b[m\n",
            "auto_phrase.sh parameters: FINRED ../../../data/FINRED/source/corpus.clean.txt 10 data/EN/wiki_quality.txt 8\n",
            "\u001b[32m===Compilation===\u001b[m\n",
            "\u001b[32m===Tokenization===\u001b[m\n",
            "\n",
            "real\t0m3.218s\n",
            "user\t0m5.683s\n",
            "sys\t0m0.400s\n",
            "Detected Language: EN\u001b[0K\n",
            "Current step: Tokenizing wikipedia phrases...\u001b[0K\n",
            "No provided expert labels.\u001b[0K\n",
            "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
            "\u001b[32m===AutoPhrasing===\u001b[m\n",
            "=== Current Settings ===\n",
            "Iterations = 2\n",
            "Minimum Support Threshold = 10\n",
            "Maximum Length Threshold = 6\n",
            "POS-Tagging Mode Disabled\n",
            "Discard Ratio = 0.050000\n",
            "Number of threads = 8\n",
            "Labeling Method = DPDN\n",
            "\tAuto labels from knowledge bases\n",
            "\tMax Positive Samples = -1\n",
            "=======\n",
            "Loading data...\n",
            "# of total tokens = 298092\n",
            "max word token id = 21607\n",
            "# of documents = 5700\n",
            "# of distinct POS tags = 0\n",
            "Mining frequent phrases...\n",
            "selected MAGIC = 21611\n",
            "# of frequent phrases = 24045\n",
            "Extracting features...\n",
            "Constructing label pools...\n",
            "\tThe size of the positive pool = 4136\n",
            "\tThe size of the negative pool = 19646\n",
            "# truth patterns = 68859\n",
            "Estimating Phrase Quality...\n",
            "Segmenting...\n",
            "Rectifying features...\n",
            "Estimating Phrase Quality...\n",
            "Segmenting...\n",
            "Dumping results...\n",
            "Done.\n",
            "\n",
            "real\t0m8.782s\n",
            "user\t0m10.510s\n",
            "sys\t0m2.105s\n",
            "\u001b[32m===Saving Model and Results===\u001b[m\n",
            "\u001b[32m===Generating Output===\u001b[m\n",
            "phrasal_segmentation.sh parameters: FINRED ../../../data/FINRED/source/corpus.clean.txt 0.5 0.9 8\n",
            "\u001b[32m===Compilation===\u001b[m\n",
            "\u001b[32m===Tokenization===\u001b[m\n",
            "\n",
            "real\t0m2.850s\n",
            "user\t0m3.909s\n",
            "sys\t0m0.189s\n",
            "Detected Language: EN\u001b[0K\n",
            "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
            "\u001b[32m===Phrasal Segmentation===\u001b[m\n",
            "=== Current Settings ===\n",
            "Segmentation Model Path = models/FINRED/segmentation.model\n",
            "After the phrasal segmentation, only following phrases will be highlighted with <phrase> and </phrase>\n",
            "\tQ(multi-word phrases) >= 0.500000\n",
            "\tQ(single-word phrases) >= 0.900000\n",
            "=======\n",
            "Length penalty model loaded.\n",
            "\tpenalty = 199.805\n",
            "# of loaded patterns = 3682\n",
            "# of loaded truth patterns = 72995\n",
            "Phrasal segmentation finished.\n",
            "   # of total highlighted quality phrases = 58442\n",
            "   # of total processed sentences = 50380\n",
            "   avg highlights per sentence = 1.16002\n",
            "\n",
            "real\t0m0.374s\n",
            "user\t0m0.345s\n",
            "sys\t0m0.025s\n",
            "\u001b[32m===Generating Output===\u001b[m\n",
            "\u001b[32m===Running NLP Feature Extraction===\u001b[m\n",
            "100% 841/841 [02:48<00:00,  4.98it/s]\n",
            "Finish NLP processing, using time 168.9690136909485 (second)\n",
            "100% 718/718 [02:59<00:00,  3.99it/s]\n",
            "Finish NLP processing, using time 179.77602434158325 (second)\n",
            "100% 685/685 [03:00<00:00,  3.80it/s]\n",
            "Finish NLP processing, using time 180.29022550582886 (second)\n",
            "100% 654/654 [03:00<00:00,  3.62it/s]\n",
            "Finish NLP processing, using time 180.46682953834534 (second)\n",
            "100% 691/691 [03:00<00:00,  3.83it/s]\n",
            "Finish NLP processing, using time 180.34758925437927 (second)\n",
            "100% 707/707 [03:00<00:00,  3.91it/s]\n",
            " 99% 749/754 [03:01<00:00, 10.64it/s]Finish NLP processing, using time 180.7711865901947 (second)\n",
            "100% 754/754 [03:01<00:00,  4.16it/s]\n",
            "Finish NLP processing, using time 181.2772262096405 (second)\n",
            "100% 650/650 [03:01<00:00,  3.58it/s]\n",
            "Finish NLP processing, using time 181.54011034965515 (second)\n",
            "\u001b[32m===Clean unnecessary files===\u001b[m\n",
            "\u001b[32m===Key Term Extraction===\u001b[m\n",
            "Extract Key Terms from Corpus: 100% 23354/23354 [00:01<00:00, 15094.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/HiExpan-master/src/featureExtraction'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCNw8ANiSBnX",
        "outputId": "dc29c9fe-b4f1-4c14-bf60-e687642222af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HiExpan-master/src/featureExtraction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The algorithm stops working on feature extraction step as it attempts to connect to Probase that has been decommisioned"
      ],
      "metadata": {
        "id": "M2Ub7QEGZ89g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x /content/HiExpan-master/src/featureExtraction/main.sh\n",
        "!./main.sh FINRED 30 remote_API 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVxlMsn8SD1C",
        "outputId": "9eb7f966-3d24-4984-b522-cc0a578c41fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m===Corpus Name: FINRED===\u001b[m\n",
            "\u001b[32m===Current Path: /content/HiExpan-master/src/featureExtraction===\u001b[m\n",
            "\u001b[32m===Extract Skipgram Features===\u001b[m\n",
            "Generating skipgram and sentence-level co-occurrence features: 100% 23354/23354 [00:01<00:00, 14864.13it/s]\n",
            "Transform Features in ../../data/FINRED/intermediate/eidSkipgramCounts.txt: 100% 208227/208227 [00:00<00:00, 211736.14it/s]\n",
            "[INFO] Start calculating TF-IDF strength\n",
            "Process (eid, feature) pairs: 100% 208227/208227 [00:01<00:00, 122662.33it/s]\n",
            "\u001b[32m===Extract Type Features (using Probase KB)===\u001b[m\n",
            "Loading entity2id.txt: 100% 6401/6401 [00:00<00:00, 287732.45it/s]\n",
            "Finish obtaining 6401 phrases, ready for entity linking\n",
            "Linking by calling remote API using 31 threads, 213 phrases/threads\n",
            "  0% 0/213 [00:00<?, ?it/s]Retrying: assault\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: friendly\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: Syriza\n",
            "Retrying: UAE\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: Shuttle\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: Greenwich\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: insurance Broker\n",
            "Retrying: Lok Sabha\n",
            "Retrying: Chevrolet Cruze\n",
            "Retrying: PALO ALTO\n",
            "Retrying: Fnac\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: 0 COMMENTS\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: Pressure\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: chief executive Brian\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: Baiju\n",
            "Retrying: writer\n",
            "Retrying: safety\n",
            "Retrying: II\n",
            "Retrying: pest control\n",
            "Retrying: mayonnaise\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: Browns\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: Earnings Releases\n",
            "Retrying: synergy\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: doctor\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: MedImmune\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: Judo\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: Amcor\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: DIRECTV\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: Nasdaq\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: Rossiya\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "Retrying: Wholesale\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "  0% 0/213 [03:57<?, ?it/s]Traceback (most recent call last):\n",
            "  File \"probase3.py\", line 271, in <module>\n",
            "    p.get_probase_parallel(phrases, num_workers = num_workers, save=True, save_file=save_file)\n",
            "\n",
            "Process ForkPoolWorker-30:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-7:\n",
            "  File \"probase3.py\", line 148, in get_probase_parallel\n",
            "    results = [p.get() for p in results]\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-6:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-26:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-17:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-15:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-23:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-2:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-18:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-13:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-14:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-10:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-8:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-22:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-4:\n",
            "  File \"probase3.py\", line 148, in <listcomp>\n",
            "    results = [p.get() for p in results]\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 651, in get\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "    self.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 648, in wait\n",
            "    self._event.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 552, in wait\n",
            "  0% 0/11 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-31:\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 296, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-25:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-20:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"probase3.py\", line 111, in get_probase_batch\n",
            "    link_res = self.get_probase_online(e)\n",
            "  File \"probase3.py\", line 74, in get_probase_online\n",
            "    response = urllib.request.urlopen( self.api_url % urllib.parse.quote(phrase, safe=''), context=ssl._create_unverified_context() ).read()\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 222, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 525, in open\n",
            "    response = self._open(req, data)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 543, in _open\n",
            "    '_open', req)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1393, in https_open\n",
            "    context=self._context, check_hostname=self._check_hostname)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1350, in do_open\n",
            "    encode_chunked=req.has_header('Transfer-encoding'))\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1443, in connect\n",
            "    super().connect()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 948, in connect\n",
            "    (self.host,self.port), self.timeout, self.source_address)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 716, in create_connection\n",
            "    sock.connect(sa)\n",
            "KeyboardInterrupt\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-11:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-29:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-3:\n",
            "Traceback (most recent call last):\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-28:\n",
            "  0% 0/213 [03:57<?, ?it/s]Traceback (most recent call last):\n",
            "\n",
            "Process ForkPoolWorker-21:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-9:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "Process ForkPoolWorker-5:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"probase3.py\", line 111, in get_probase_batch\n",
            "    link_res = self.get_probase_online(e)\n",
            "  File \"probase3.py\", line 74, in get_probase_online\n",
            "    response = urllib.request.urlopen( self.api_url % urllib.parse.quote(phrase, safe=''), context=ssl._create_unverified_context() ).read()\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 222, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 525, in open\n",
            "    response = self._open(req, data)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 543, in _open\n",
            "    '_open', req)\n",
            "  File \"probase3.py\", line 111, in get_probase_batch\n",
            "    link_res = self.get_probase_online(e)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"probase3.py\", line 74, in get_probase_online\n",
            "    response = urllib.request.urlopen( self.api_url % urllib.parse.quote(phrase, safe=''), context=ssl._create_unverified_context() ).read()\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1393, in https_open\n",
            "    context=self._context, check_hostname=self._check_hostname)\n",
            "  0% 0/213 [03:57<?, ?it/s]  File \"/usr/lib/python3.7/urllib/request.py\", line 222, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1350, in do_open\n",
            "    encode_chunked=req.has_header('Transfer-encoding'))\n",
            "\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 525, in open\n",
            "    response = self._open(req, data)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 543, in _open\n",
            "    '_open', req)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"probase3.py\", line 111, in get_probase_batch\n",
            "    link_res = self.get_probase_online(e)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1393, in https_open\n",
            "    context=self._context, check_hostname=self._check_hostname)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"probase3.py\", line 74, in get_probase_online\n",
            "    response = urllib.request.urlopen( self.api_url % urllib.parse.quote(phrase, safe=''), context=ssl._create_unverified_context() ).read()\n",
            "Process ForkPoolWorker-24:\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1350, in do_open\n",
            "    encode_chunked=req.has_header('Transfer-encoding'))\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1443, in connect\n",
            "    super().connect()\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 222, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 948, in connect\n",
            "    (self.host,self.port), self.timeout, self.source_address)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 525, in open\n",
            "    response = self._open(req, data)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 716, in create_connection\n",
            "    sock.connect(sa)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 543, in _open\n",
            "    '_open', req)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1393, in https_open\n",
            "    context=self._context, check_hostname=self._check_hostname)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1350, in do_open\n",
            "    encode_chunked=req.has_header('Transfer-encoding'))\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1443, in connect\n",
            "    super().connect()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 948, in connect\n",
            "    (self.host,self.port), self.timeout, self.source_address)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 716, in create_connection\n",
            "    sock.connect(sa)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1443, in connect\n",
            "    super().connect()\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 948, in connect\n",
            "    (self.host,self.port), self.timeout, self.source_address)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 716, in create_connection\n",
            "    sock.connect(sa)\n",
            "KeyboardInterrupt\n",
            "Process ForkPoolWorker-16:\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-27:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"probase3.py\", line 111, in get_probase_batch\n",
            "    link_res = self.get_probase_online(e)\n",
            "  File \"probase3.py\", line 74, in get_probase_online\n",
            "    response = urllib.request.urlopen( self.api_url % urllib.parse.quote(phrase, safe=''), context=ssl._create_unverified_context() ).read()\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 222, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 525, in open\n",
            "    response = self._open(req, data)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 543, in _open\n",
            "    '_open', req)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1393, in https_open\n",
            "    context=self._context, check_hostname=self._check_hostname)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1350, in do_open\n",
            "    encode_chunked=req.has_header('Transfer-encoding'))\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1443, in connect\n",
            "    super().connect()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 948, in connect\n",
            "    (self.host,self.port), self.timeout, self.source_address)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 716, in create_connection\n",
            "    sock.connect(sa)\n",
            "KeyboardInterrupt\n",
            "  0% 0/213 [03:57<?, ?it/s]\n",
            "Process ForkPoolWorker-12:\n",
            "Process ForkPoolWorker-19:\n",
            "Process ForkPoolWorker-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"probase3.py\", line 111, in get_probase_batch\n",
            "    link_res = self.get_probase_online(e)\n",
            "  File \"probase3.py\", line 74, in get_probase_online\n",
            "    response = urllib.request.urlopen( self.api_url % urllib.parse.quote(phrase, safe=''), context=ssl._create_unverified_context() ).read()\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 222, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 525, in open\n",
            "    response = self._open(req, data)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 543, in _open\n",
            "    '_open', req)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1393, in https_open\n",
            "    context=self._context, check_hostname=self._check_hostname)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1350, in do_open\n",
            "    encode_chunked=req.has_header('Transfer-encoding'))\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1443, in connect\n",
            "    super().connect()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 948, in connect\n",
            "    (self.host,self.port), self.timeout, self.source_address)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 716, in create_connection\n",
            "    sock.connect(sa)\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"probase3.py\", line 111, in get_probase_batch\n",
            "    link_res = self.get_probase_online(e)\n",
            "  File \"probase3.py\", line 74, in get_probase_online\n",
            "    response = urllib.request.urlopen( self.api_url % urllib.parse.quote(phrase, safe=''), context=ssl._create_unverified_context() ).read()\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 222, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 525, in open\n",
            "    response = self._open(req, data)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 543, in _open\n",
            "    '_open', req)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1393, in https_open\n",
            "    context=self._context, check_hostname=self._check_hostname)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1350, in do_open\n",
            "    encode_chunked=req.has_header('Transfer-encoding'))\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1443, in connect\n",
            "    super().connect()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 948, in connect\n",
            "    (self.host,self.port), self.timeout, self.source_address)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 716, in create_connection\n",
            "    sock.connect(sa)\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"probase3.py\", line 111, in get_probase_batch\n",
            "    link_res = self.get_probase_online(e)\n",
            "  File \"probase3.py\", line 74, in get_probase_online\n",
            "    response = urllib.request.urlopen( self.api_url % urllib.parse.quote(phrase, safe=''), context=ssl._create_unverified_context() ).read()\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 222, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 525, in open\n",
            "    response = self._open(req, data)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 543, in _open\n",
            "    '_open', req)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 503, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1393, in https_open\n",
            "    context=self._context, check_hostname=self._check_hostname)\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 1350, in do_open\n",
            "    encode_chunked=req.has_header('Transfer-encoding'))\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1443, in connect\n",
            "    super().connect()\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 948, in connect\n",
            "    (self.host,self.port), self.timeout, self.source_address)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 716, in create_connection\n",
            "    sock.connect(sa)\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"extractTypeFeature.py\", line 32, in <module>\n",
            "    with open(probaseLinkedFile) as fin:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '../../data/FINRED/intermediate/linked_results.txt'\n",
            "Traceback (most recent call last):\n",
            "  File \"transformFeatures.py\", line 70, in <module>\n",
            "    main()\n",
            "  File \"transformFeatures.py\", line 66, in main\n",
            "    calculate_TFIDF_strength_new(inputFileName, outputFileName)\n",
            "  File \"transformFeatures.py\", line 29, in calculate_TFIDF_strength_new\n",
            "    with open(inputFileName, \"r\") as fin:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '../../data/FINRED/intermediate/eidTypeCounts.txt'\n",
            "\u001b[32m===Extract Document-level Co-occurrence Features===\u001b[m\n",
            "Generate document-level cooccurrence features (pass 1): 100% 23354/23354 [00:00<00:00, 49613.73it/s]\n",
            "Generate document-level coocurrence features (pass 2): 100% 5700/5700 [00:00<00:00, 10344.30it/s]\n",
            "\u001b[32m===Extract Embedding Features (using word2vec)===\u001b[m\n",
            "loading corpus for word2vec training: 100% 23354/23354 [00:00<00:00, 23407.46it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"learnEmbedFeature.py\", line 131, in <module>\n",
            "    alpha=0.025, min_alpha=0.025 * 0.0001, sample=1e-3, iter=5, trim_rule=trim_rule)\n",
            "TypeError: __init__() got an unexpected keyword argument 'size'\n"
          ]
        }
      ]
    }
  ]
}